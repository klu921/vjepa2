### Task:

I want you to create a multimodel ML model interactive framework  using existing models on huggingface that can caption image freeze-frames, then use those captions to answer questions. The goal is that it should be able to semantically understand the video, so that when I ask analytical questions about the video later on, it can answer them. 

I suggest taking frames every 3 seconds, captioning them in detail. I want this to beceome an offline representatino, meaning you can only pass through one time, and then make query from that single pass-through. So be extremely fetailed. The demo video we're using can be found in the video.mp4 file in this folder. Do it in a way where the user can ask questions such as, 'Why did the camera wearer use the red towel?'.

And then, make it queryable. So, if I ask it a multiple choice question, I want a response. 

Be systematic, organized, and keep everything in the claude_demo folder. Ask me if you have any questions.

Also, keep a todo list file that I can see, and update it when you act. And keep a list of mistakes you might have made or behaviors that cause bugs, and update that as well.